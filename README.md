# üìú El Or√°culo del Quijote üñãÔ∏è

## Descripci√≥n del Proyecto

**El Or√°culo del Quijote** es una aplicaci√≥n web interactiva que utiliza un modelo de lenguaje de inteligencia artificial fine-tuneado para responder preguntas sobre la aclamada obra de Miguel de Cervantes, **"Don Quijote de la Mancha"**.

El coraz√≥n de este proyecto es el modelo **Qwen1.5-1.8B-Chat** de Qwen, que ha sido **sintonizado (fine-tuned)** con el texto completo del libro. Gracias a este entrenamiento especializado, el modelo ha aprendido el estilo, los personajes y los eventos de la obra, permiti√©ndole generar respuestas precisas y contextualmente relevantes a las preguntas del usuario.

## Caracter√≠sticas

* **Respuestas Contextuales**: El modelo responde a las preguntas utilizando el conocimiento adquirido de la obra, ofreciendo informaci√≥n sobre personajes, tramas, y la filosof√≠a del libro.
* **Interacci√≥n Sencilla**: La interfaz de usuario, construida con **Streamlit**, es intuitiva y f√°cil de usar, permitiendo a cualquier persona interactuar con el modelo sin necesidad de conocimientos t√©cnicos.
* **Despliegue Eficiente**: El proyecto utiliza **Git LFS** para gestionar el modelo de gran tama√±o en GitHub y se despliega en **Streamlit Cloud**, optimizando la carga y el rendimiento de la aplicaci√≥n.
* **QLoRA Fine-Tuning**: El modelo fue entrenado con **QLoRA** (Quantized Low-Rank Adaptation), una t√©cnica de fine-tuning eficiente que permite adaptar modelos grandes con recursos de hardware limitados.

## Estructura del Repositorio

.
‚îú‚îÄ‚îÄ .streamlit/  # Carpeta opcional de configuraci√≥n de Streamlit
‚îú‚îÄ‚îÄ app.py       # Archivo principal de la aplicaci√≥n
‚îú‚îÄ‚îÄ requirements.txt # Dependencias de Python
‚îú‚îÄ‚îÄ qwen-quijote-finetuned/ # Carpeta del modelo fine-tuneado (rastreado por Git LFS)
‚îî‚îÄ‚îÄ README.md

## Gu√≠a de Uso

Puedes acceder a la aplicaci√≥n en vivo [aqu√≠](https://tu-usuario.streamlit.app) (¬°reemplaza este enlace con el de tu aplicaci√≥n desplegada!).

Para usar la aplicaci√≥n:
1.  Ingresa tu pregunta sobre la obra en el cuadro de texto.
2.  Haz clic en el bot√≥n "Obtener Respuesta".
3.  Espera unos segundos mientras el modelo genera la respuesta.

## C√≥mo Funciona

1.  **Modelo Fine-Tuneado**: El modelo base Qwen1.5-1.8B-Chat fue sintonizado con el libro "Don Quijote de la Mancha" en un entorno de **Google Colab**, utilizando una GPU T4 y la t√©cnica QLoRA para optimizar el uso de recursos.
2.  **Manejo de Archivos Grandes**: La carpeta del modelo (`qwen-quijote-finetuned/`) se almacena en este repositorio utilizando **Git LFS**, lo que permite subir archivos que exceden el l√≠mite de tama√±o de GitHub.
3.  **Despliegue con Streamlit Cloud**: Streamlit Cloud clona este repositorio, lee el archivo `requirements.txt` para instalar las dependencias y ejecuta `app.py` para poner la aplicaci√≥n en l√≠nea. La funci√≥n de cach√© de Streamlit (`@st.cache_resource`) asegura que el modelo solo se cargue una vez por sesi√≥n, mejorando la experiencia del usuario.

## Requisitos y Tecnolog√≠as

* **Lenguaje de Programaci√≥n**: Python
* **Modelo Base**: [Qwen1.5-1.8B-Chat](https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat)
* **Framework de IA**: `transformers`, `peft`, `bitsandbytes`, `trl`
* **Interfaz de Usuario**: Streamlit
* **Control de Versiones**: Git LFS

## Contacto y Contribuci√≥n

Si deseas contribuir al proyecto o tienes alguna pregunta, no dudes en abrir un *issue* o una *pull request* en este repositorio.

---
¬© 2025 [sareizat-dev]. Todos los derechos reservados.
